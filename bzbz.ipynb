{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2718383",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "import pandas as pd\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64bf744c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize wandb API\n",
    "api = wandb.Api()\n",
    "\n",
    "# Specify your entity and project name\n",
    "entity = \"\"  # Replace with your wandb username or team name\n",
    "project = \"\"  # Replace with your project name\n",
    "\n",
    "# Get all runs from the project\n",
    "runs = api.runs(f\"{entity}/{project}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "498206c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Fetch data from all runs\n",
    "all_data = []\n",
    "for run in runs:\n",
    "    run_data = {\n",
    "        'name': run.name,\n",
    "        'id': run.id,\n",
    "        'state': run.state,\n",
    "        'created_at': run.created_at,\n",
    "        'config': run.config,\n",
    "        'summary': run.summary._json_dict,\n",
    "        'history': run.history().to_dict('records')\n",
    "    }\n",
    "    all_data.append(run_data)\n",
    "\n",
    "print(f\"Fetched data from {len(all_data)} runs\")\n",
    "\n",
    "df = pd.DataFrame(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "387abf62",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"wandb_runs_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e3a321",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"wandb_runs_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c746b56e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "866ef38b",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_name_1 = \"\"\n",
    "run_name_2 = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22197228",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_run_row(df, run_name):\n",
    "    return df[df['name'] == run_name].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82320d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_1 = get_run_row(df, run_name_1)\n",
    "run_2 = get_run_row(df, run_name_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96e30e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval(run_row.config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be7042c",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval(run_1.summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26963c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_1.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c47fb0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(df.iloc[1]['history'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d452c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "import ast\n",
    "\n",
    "# Create a dropdown widget for selecting run\n",
    "run_dropdown = widgets.Dropdown(\n",
    "    options=[(f\"{row['name']} (id: {row['id']})\", idx) for idx, row in df.iterrows()],\n",
    "    value=0,\n",
    "    description='Select Run:',\n",
    "    style={'description_width': 'initial'},\n",
    "    layout=widgets.Layout(width='500px')\n",
    ")\n",
    "\n",
    "# Create output widget for the plot\n",
    "output = widgets.Output()\n",
    "\n",
    "def update_plot(change):\n",
    "    with output:\n",
    "        output.clear_output(wait=True)\n",
    "        \n",
    "        # Get history for selected run\n",
    "        history_data = df.iloc[change['new']]['history']\n",
    "        print(history_data)\n",
    "        \n",
    "        \n",
    "        hist = pd.DataFrame(history_data)\n",
    "        \n",
    "        # Get available numeric columns from the history dataframe\n",
    "        numeric_columns = hist.select_dtypes(include=['float64', 'int64']).columns.tolist()\n",
    "        # Remove timestamp and step columns as they're typically x-axis values\n",
    "        plot_columns = [col for col in numeric_columns if col not in ['_timestamp', '_step', 'train/global_step']]\n",
    "        \n",
    "        # Filter out columns that are all NaN\n",
    "        plot_columns = [col for col in plot_columns if hist[col].notna().any()]\n",
    "        \n",
    "        if not plot_columns:\n",
    "            print(\"No plottable data found\")\n",
    "            return\n",
    "        \n",
    "        # Create figure with dropdown menu\n",
    "        fig = go.Figure()\n",
    "        \n",
    "        # Add traces for each column (initially all hidden except the first)\n",
    "        for i, col in enumerate(plot_columns):\n",
    "            fig.add_trace(\n",
    "                go.Scatter(\n",
    "                    x=hist.index,\n",
    "                    y=hist[col],\n",
    "                    name=col,\n",
    "                    visible=(i == 0)  # Only first trace is visible initially\n",
    "                )\n",
    "            )\n",
    "        \n",
    "        # Create dropdown menu buttons\n",
    "        buttons = []\n",
    "        for i, col in enumerate(plot_columns):\n",
    "            visible = [False] * len(plot_columns)\n",
    "            visible[i] = True\n",
    "            buttons.append(\n",
    "                dict(\n",
    "                    label=col,\n",
    "                    method=\"update\",\n",
    "                    args=[{\"visible\": visible},\n",
    "                          {\"title\": f\"{df.iloc[change['new']]['name']} - {col}\"}]\n",
    "                )\n",
    "            )\n",
    "        \n",
    "        # Add dropdown menu\n",
    "        fig.update_layout(\n",
    "            updatemenus=[\n",
    "                dict(\n",
    "                    active=0,\n",
    "                    buttons=buttons,\n",
    "                    direction=\"down\",\n",
    "                    showactive=True,\n",
    "                    x=0.1,\n",
    "                    xanchor=\"left\",\n",
    "                    y=1.15,\n",
    "                    yanchor=\"top\"\n",
    "                )\n",
    "            ],\n",
    "            title=f\"{df.iloc[change['new']]['name']} - {plot_columns[0]}\",\n",
    "            xaxis_title=\"Step\",\n",
    "            yaxis_title=\"Value\",\n",
    "            height=600\n",
    "        )\n",
    "        \n",
    "        fig.show()\n",
    "\n",
    "# Set up observer\n",
    "run_dropdown.observe(update_plot, names='value')\n",
    "\n",
    "# Display widgets\n",
    "display(run_dropdown)\n",
    "display(output)\n",
    "\n",
    "# Initial plot\n",
    "update_plot({'new': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "369c3d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = df[df[\"name\"] == \"\"].iloc[0][\"history\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be7c51d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b1deca",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = pd.DataFrame(hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebe5f5c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23f18d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_loss = hist[[\"train/global_step\", \"train/loss\"]]\n",
    "\n",
    "hist_loss[\"loss_smoothed\"] = hist_loss[\"train/loss\"].rolling(window=2).mean()\n",
    "\n",
    "hist_loss[\"gradient\"] = hist_loss[\"train/loss\"].diff()\n",
    "\n",
    "px.line(hist_loss, x=\"train/global_step\", y=[\"train/loss\", \"loss_smoothed\", \"gradient\"], title=\"Training Loss with Smoothing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4385b148",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Peak Detection using scipy.signal.find_peaks (STRICT)\n",
    "from scipy.signal import find_peaks\n",
    "import numpy as np\n",
    "\n",
    "# Find peaks in training loss\n",
    "loss_data = hist_loss[\"train/loss\"].values\n",
    "steps = hist_loss[\"train/global_step\"].values\n",
    "\n",
    "# Calculate adaptive thresholds for stricter detection\n",
    "loss_mean = np.mean(loss_data)\n",
    "loss_std = np.std(loss_data)\n",
    "# min_height = loss_mean + 0.5 * loss_std  # Only peaks above mean + 0.5 std\n",
    "\n",
    "# Find peaks with STRICT parameters\n",
    "peaks, properties = find_peaks(\n",
    "    loss_data, \n",
    "    # height=min_height,    # Minimum height - only significant peaks\n",
    "    threshold=None,       # Required threshold of peaks\n",
    "    distance=10,          # Increased distance between peaks (was 5)\n",
    "    prominence=1,       # Increased prominence requirement (was 0.01)\n",
    "    width=2,              # Minimum width of peaks\n",
    "    wlen=None,            # Window length for prominence calculation\n",
    "    rel_height=0.5        # Relative height for width calculation\n",
    ")\n",
    "\n",
    "# Create plot\n",
    "fig = px.line(hist_loss, x=\"train/global_step\", y=\"train/loss\", title=\"Training Loss with Strict Peak Detection\")\n",
    "\n",
    "# # Add horizontal line showing minimum height threshold\n",
    "# fig.add_hline(y=min_height, line_dash=\"dash\", line_color=\"gray\", \n",
    "#               annotation_text=f\"Min Height: {min_height:.4f}\")\n",
    "\n",
    "# Add peaks\n",
    "if len(peaks) > 0:\n",
    "    peak_steps = steps[peaks]\n",
    "    peak_values = loss_data[peaks]\n",
    "    \n",
    "    fig.add_scatter(\n",
    "        x=peak_steps,\n",
    "        y=peak_values,\n",
    "        mode='markers',\n",
    "        marker=dict(color='red', size=12, symbol='triangle-up'),\n",
    "        name=f'Strict Peaks ({len(peaks)})'\n",
    "    )\n",
    "\n",
    "fig.show()\n",
    "\n",
    "# Print peak information\n",
    "print(f\"Found {len(peaks)} strict peaks:\")\n",
    "print(f\"Detection criteria:\")\n",
    "# print(f\"  - Minimum height: {min_height:.4f}\")\n",
    "print(f\"  - Minimum distance: 20 steps\")\n",
    "print(f\"  - Minimum prominence: 0.1\")\n",
    "print(f\"  - Minimum width: 3 steps\")\n",
    "\n",
    "if len(peaks) > 0:\n",
    "    for i, peak_idx in enumerate(peaks):\n",
    "        step = steps[peak_idx]\n",
    "        value = loss_data[peak_idx]\n",
    "        prominence = properties['prominences'][i] if 'prominences' in properties else 'N/A'\n",
    "        width = properties['widths'][i] if 'widths' in properties else 'N/A'\n",
    "        print(f\"  Peak {i+1}: Step {step}, Loss = {value:.4f}, Prominence = {prominence:.4f}, Width = {width:.1f}\")\n",
    "else:\n",
    "    print(\"  No strict peaks detected\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6a8de1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist[\"train/loss\"].diff().diff().diff().diff().plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ab6210",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_train_loss(history):\n",
    "    hist = pd.DataFrame(history)\n",
    "    fig = px.line(hist, y=\"eval/loss\", title=\"Training Loss Over Time\")\n",
    "    return fig\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fcdaac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_train_loss(df.iloc[3][\"history\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47b588c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b6d1c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's examine the structure of the data\n",
    "print(\"DataFrame shape:\", df.shape)\n",
    "print(\"DataFrame columns:\", df.columns.tolist())\n",
    "print(\"\\nFirst run info:\")\n",
    "print(\"Name:\", df.iloc[0]['name'])\n",
    "print(\"History type:\", type(df.iloc[0]['history']))\n",
    "print(\"History sample:\", str(df.iloc[0]['history'])[:200] + \"...\" if len(str(df.iloc[0]['history'])) > 200 else str(df.iloc[0]['history']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a37d678a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's debug the metric detection issue\n",
    "import ast\n",
    "\n",
    "def debug_parse_history(history_str):\n",
    "    \"\"\"Debug version of parse_history\"\"\"\n",
    "    try:\n",
    "        if isinstance(history_str, str):\n",
    "            history_list = ast.literal_eval(history_str)\n",
    "        else:\n",
    "            history_list = history_str\n",
    "        \n",
    "        if history_list and len(history_list) > 0:\n",
    "            hist_df = pd.DataFrame(history_list)\n",
    "            print(f\"Parsed DataFrame shape: {hist_df.shape}\")\n",
    "            print(f\"Columns: {hist_df.columns.tolist()}\")\n",
    "            print(f\"Numeric columns: {hist_df.select_dtypes(include=['float64', 'int64']).columns.tolist()}\")\n",
    "            return hist_df\n",
    "        else:\n",
    "            print(\"Empty history list\")\n",
    "            return pd.DataFrame()\n",
    "    except Exception as e:\n",
    "        print(f\"Error parsing history: {e}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "# Test with first run\n",
    "print(\"=== Debugging first run ===\")\n",
    "first_run = df.iloc[0]\n",
    "print(f\"Run name: {first_run['name']}\")\n",
    "debug_hist = debug_parse_history(first_run['history'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9145b765",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see what's actually in the history string\n",
    "history_sample = df.iloc[0]['history']\n",
    "print(\"History type:\", type(history_sample))\n",
    "print(\"First 500 characters:\")\n",
    "print(repr(history_sample[:500]))\n",
    "print(\"\\nLast 200 characters:\")\n",
    "print(repr(history_sample[-200:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "300ea24a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the fixed parsing function\n",
    "def parse_history_fixed(history_str):\n",
    "    \"\"\"Parse history string into DataFrame\"\"\"\n",
    "    try:\n",
    "        if isinstance(history_str, str):\n",
    "            # Replace 'nan' with 'None' to make it parseable\n",
    "            cleaned_str = history_str.replace('nan', 'None')\n",
    "            history_list = ast.literal_eval(cleaned_str)\n",
    "        else:\n",
    "            history_list = history_str\n",
    "        \n",
    "        if history_list and len(history_list) > 0:\n",
    "            df_hist = pd.DataFrame(history_list)\n",
    "            # Convert None back to NaN\n",
    "            df_hist = df_hist.replace({None: np.nan})\n",
    "            return df_hist\n",
    "        else:\n",
    "            return pd.DataFrame()\n",
    "    except Exception:\n",
    "        # If ast.literal_eval fails, try eval as a last resort\n",
    "        try:\n",
    "            if isinstance(history_str, str):\n",
    "                # Create a safe environment for eval\n",
    "                safe_dict = {\"nan\": float('nan'), \"__builtins__\": {}}\n",
    "                history_list = eval(history_str, safe_dict)\n",
    "                if history_list and len(history_list) > 0:\n",
    "                    return pd.DataFrame(history_list)\n",
    "            return pd.DataFrame()\n",
    "        except Exception:\n",
    "            return pd.DataFrame()\n",
    "\n",
    "# Test with the first run\n",
    "print(\"Testing fixed parsing...\")\n",
    "test_hist = parse_history_fixed(df.iloc[0]['history'])\n",
    "print(f\"Success! Shape: {test_hist.shape}\")\n",
    "print(f\"Columns: {test_hist.columns.tolist()}\")\n",
    "print(f\"Numeric columns: {test_hist.select_dtypes(include=[np.number]).columns.tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc95438d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Test getting all available metrics\n",
    "def get_available_metrics_fixed(df):\n",
    "    \"\"\"Get all available metrics from all runs\"\"\"\n",
    "    all_metrics = set()\n",
    "    \n",
    "    for idx, row in df.iterrows():\n",
    "        hist_df = parse_history_fixed(row['history'])\n",
    "        if not hist_df.empty:\n",
    "            # Get numeric columns (exclude timestamp and step columns for metric selection)\n",
    "            numeric_cols = hist_df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "            all_metrics.update(numeric_cols)\n",
    "    \n",
    "    # Remove common non-metric columns\n",
    "    exclude_cols = {'_timestamp', '_runtime', '_step'}\n",
    "    all_metrics = all_metrics - exclude_cols\n",
    "    \n",
    "    return sorted(list(all_metrics))\n",
    "\n",
    "print(\"Testing metric detection...\")\n",
    "available_metrics = get_available_metrics_fixed(df)\n",
    "print(f\"Found {len(available_metrics)} metrics:\")\n",
    "for metric in available_metrics:\n",
    "    print(f\"  - {metric}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "094031bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the trimming functionality\n",
    "sample_data = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "print(\"Original data:\", sample_data)\n",
    "\n",
    "# Test percentage trimming (20%)\n",
    "skip_percentage = 20\n",
    "skip_count = int(len(sample_data) * skip_percentage / 100)\n",
    "trimmed_data = sample_data[skip_count:]\n",
    "print(f\"After {skip_percentage}% trimming (skip {skip_count} rows):\", trimmed_data)\n",
    "\n",
    "# Test fixed trimming (3 rows)\n",
    "skip_rows = 3\n",
    "trimmed_data_fixed = sample_data[skip_rows:]\n",
    "print(f\"After skipping {skip_rows} rows:\", trimmed_data_fixed)\n",
    "\n",
    "print(\"\\nâœ… Trimming logic works correctly!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "metric",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
